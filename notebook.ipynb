{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Interpreter\n",
    "We train a simple transformer for sentiment analysis on movie reviews, extract interpretable features using SAE and generate explanations using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataPreprocessing import *\n",
    "import pandas as pd\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/'\n",
    "train_pos, train_neg, test_pos, test_neg = [], [], [], []\n",
    "sets_dict = {'train/pos/': train_pos, 'train/neg/': train_neg, 'test/pos/': test_pos, 'test/neg/': test_neg}\n",
    "for dataset in sets_dict:\n",
    "        file_list = [f for f in os.listdir(os.path.join(path, dataset)) if f.endswith('.txt')]\n",
    "        load_data(os.path.join(path, dataset), file_list, sets_dict[dataset])\n",
    "train_data = pd.concat([pd.DataFrame({'review': train_pos, 'label':1}), pd.DataFrame({'review': train_neg, 'label':0})], axis = 0, ignore_index=True)\n",
    "test_data = pd.concat([pd.DataFrame({'review': test_pos, 'label':1}), pd.DataFrame({'review': test_neg, 'label':0})], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  For a movie that gets no respect there sure ar...      1\n",
      "1  Bizarre horror movie filled with famous faces ...      1\n",
      "2  A solid, if unremarkable film. Matthau, as Ein...      1\n",
      "3  It's a strange feeling to sit alone in a theat...      1\n",
      "4  You probably all already know this by now, but...      1\n",
      "                                                  review  label\n",
      "24995  My comments may be a bit of a spoiler, for wha...      0\n",
      "24996  The \"saucy\" misadventures of four au pairs who...      0\n",
      "24997  Oh, those Italians! Assuming that movies about...      0\n",
      "24998  Eight academy nominations? It's beyond belief....      0\n",
      "24999  Not that I dislike childrens movies, but this ...      0\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  Based on an actual story, John Boorman shows t...      1\n",
      "1  This is a gem. As a Film Four production - the...      1\n",
      "2  I really like this show. It has drama, romance...      1\n",
      "3  This is the best 3-D experience Disney has at ...      1\n",
      "4  Of the Korean movies I've seen, only three had...      1\n",
      "                                                  review  label\n",
      "24995  With actors like Depardieu and Richard it is r...      0\n",
      "24996  If you like to get a couple of fleeting glimps...      0\n",
      "24997  When something can be anything you want it to ...      0\n",
      "24998  I had heard good things about \"States of Grace...      0\n",
      "24999  Well, this movie actually did have one redeemi...      0\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(test_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tokenized\"] = train_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))\n",
    "test_data[\"tokenized\"] = test_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  label  \\\n",
      "0  For a movie that gets no respect there sure ar...      1   \n",
      "1  Bizarre horror movie filled with famous faces ...      1   \n",
      "2  A solid, if unremarkable film. Matthau, as Ein...      1   \n",
      "3  It's a strange feeling to sit alone in a theat...      1   \n",
      "4  You probably all already know this by now, but...      1   \n",
      "\n",
      "                                           tokenized  \n",
      "0  [for, a, movie, that, gets, no, respect, there...  \n",
      "1  [bizarre, horror, movie, filled, with, famous,...  \n",
      "2  [a, solid, ,, if, unremarkable, film, ., matth...  \n",
      "3  [it, 's, a, strange, feeling, to, sit, alone, ...  \n",
      "4  [you, probably, all, already, know, this, by, ...  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voacb Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reversed_train_vocab = generate_vocab_map(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "train_dataset = ReviewDataset(train_vocab, train_data)\n",
    "test_dataset  = ReviewDataset(train_vocab, test_data)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "test_sampler  = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
