{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Interpreter\n",
    "We train a simple transformer for sentiment analysis on movie reviews, extract interpretable features using SAE and generate explanations using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataPreprocessing import *\n",
    "import pandas as pd\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data\n",
    "Data is loaded from 'dataset' folder. There are 50,000 reviews in the data total. 25,000 for training and 25,000 testing. Reviews have label, either positive or negative. There are an equal number of positive and negative reviews in the each dataset. Each review is a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder path were dataset is located\n",
    "path = 'dataset/'\n",
    "#initialize empty lists to hold data\n",
    "train_pos, train_neg, test_pos, test_neg = [], [], [], []\n",
    "#create a dictionary where the key is the relative path to data and value is empty list\n",
    "sets_dict = {'train/pos/': train_pos, 'train/neg/': train_neg, 'test/pos/': test_pos, 'test/neg/': test_neg}\n",
    "#loop through dictionary to read from files and populate empty lists\n",
    "for dataset in sets_dict:\n",
    "        file_list = [file for file in os.listdir(os.path.join(path, dataset)) if file.endswith('.txt')]\n",
    "        load_data(os.path.join(path, dataset), file_list, sets_dict[dataset])\n",
    "#Covert lists to pandas dataframes and combine to form train and test datasets\n",
    "train_data = pd.concat([pd.DataFrame({'review': train_pos, 'label':1}), pd.DataFrame({'review': train_neg, 'label':0})], axis = 0, ignore_index=True)\n",
    "test_data = pd.concat([pd.DataFrame({'review': test_pos, 'label':1}), pd.DataFrame({'review': test_neg, 'label':0})], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  For a movie that gets no respect there sure ar...      1\n",
      "1  Bizarre horror movie filled with famous faces ...      1\n",
      "2  A solid, if unremarkable film. Matthau, as Ein...      1\n",
      "3  It's a strange feeling to sit alone in a theat...      1\n",
      "4  You probably all already know this by now, but...      1\n",
      "                                                  review  label\n",
      "24995  My comments may be a bit of a spoiler, for wha...      0\n",
      "24996  The \"saucy\" misadventures of four au pairs who...      0\n",
      "24997  Oh, those Italians! Assuming that movies about...      0\n",
      "24998  Eight academy nominations? It's beyond belief....      0\n",
      "24999  Not that I dislike childrens movies, but this ...      0\n"
     ]
    }
   ],
   "source": [
    "#Visualize train_data dataframe\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  Based on an actual story, John Boorman shows t...      1\n",
      "1  This is a gem. As a Film Four production - the...      1\n",
      "2  I really like this show. It has drama, romance...      1\n",
      "3  This is the best 3-D experience Disney has at ...      1\n",
      "4  Of the Korean movies I've seen, only three had...      1\n",
      "                                                  review  label\n",
      "24995  With actors like Depardieu and Richard it is r...      0\n",
      "24996  If you like to get a couple of fleeting glimps...      0\n",
      "24997  When something can be anything you want it to ...      0\n",
      "24998  I had heard good things about \"States of Grace...      0\n",
      "24999  Well, this movie actually did have one redeemi...      0\n"
     ]
    }
   ],
   "source": [
    "#Visualize test_data dataframe\n",
    "print(test_data.shape)\n",
    "print(test_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Data\n",
    "Tokenize each review using spacy english tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tokenized\"] = train_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))\n",
    "test_data[\"tokenized\"] = test_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [for, a, movie, that, gets, no, respect, there...\n",
      "1    [bizarre, horror, movie, filled, with, famous,...\n",
      "2    [a, solid, ,, if, unremarkable, film, ., matth...\n",
      "3    [it, 's, a, strange, feeling, to, sit, alone, ...\n",
      "4    [you, probably, all, already, know, this, by, ...\n",
      "Name: tokenized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Examine tokenized reviews\n",
    "print(train_data.head()[\"tokenized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voacb Map\n",
    "Create a vocab map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reversed_train_vocab = generate_vocab_map(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "train_dataset = ReviewDataset(train_vocab, train_data)\n",
    "test_dataset  = ReviewDataset(train_vocab, test_data)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "test_sampler  = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
