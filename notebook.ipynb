{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Interpreter\n",
    "We train a simple transformer for sentiment analysis on movie reviews, extract interpretable features using SAE and generate explanations using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataPreprocessing import *\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, model_name, loss_fn='ce'):\n",
    "    file_path = os.path.join(os.getcwd(), 'model_weights', f'checkpoint_{model_name}_{loss_fn}.pt')\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'model_weights'), exist_ok=True)\n",
    "    checkpoint = { # create a dictionary with all the state information\n",
    "        'model_state_dict': model.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Checkpoint saved to {file_path}\")\n",
    "\n",
    "def load_checkpoint(model, model_name, loss_fn='ce', map_location='cpu'):\n",
    "    file_path = os.path.join(os.getcwd(), 'model_weights', f'checkpoint_{model_name}_{loss_fn}.pt')\n",
    "    checkpoint = torch.load(file_path, map_location=map_location) # load the checkpoint, ensure correct device\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss_over_time, val_loss_over_time, model_name):\n",
    "    epochs = range(1, len(train_loss_over_time) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss_over_time, color='red', label='Train Loss')\n",
    "    plt.plot(epochs, val_loss_over_time, color='blue', label='Val Loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss for {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data\n",
    "Data is loaded from 'dataset' folder. There are 50,000 reviews in the data total. 25,000 for training and 25,000 testing. Reviews have label, either positive or negative. There are an equal number of positive and negative reviews in the each dataset. Each review is a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder path were dataset is located\n",
    "path = 'dataset/'\n",
    "#initialize empty lists to hold data\n",
    "train_pos, train_neg, test_pos, test_neg = [], [], [], []\n",
    "#create a dictionary where the key is the relative path to data and value is empty list\n",
    "sets_dict = {'train/pos/': train_pos, 'train/neg/': train_neg, 'test/pos/': test_pos, 'test/neg/': test_neg}\n",
    "#loop through dictionary to read from files and populate empty lists\n",
    "for dataset in sets_dict:\n",
    "        file_list = [file for file in os.listdir(os.path.join(path, dataset)) if file.endswith('.txt')]\n",
    "        file_list = sorted(file_list)\n",
    "        load_data(os.path.join(path, dataset), file_list, sets_dict[dataset])\n",
    "#Covert lists to pandas dataframes and combine to form train and test datasets\n",
    "train_data = pd.concat([pd.DataFrame({'review': train_pos, 'label':1}), pd.DataFrame({'review': train_neg, 'label':0})], axis = 0, ignore_index=True)\n",
    "test_data = pd.concat([pd.DataFrame({'review': test_pos, 'label':1}), pd.DataFrame({'review': test_neg, 'label':0})], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize train_data dataframe\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize test_data dataframe\n",
    "print(test_data.shape)\n",
    "print(test_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Data\n",
    "Tokenize each review using spacy english tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tokenized\"] = train_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))\n",
    "test_data[\"tokenized\"] = test_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine tokenized reviews\n",
    "print(train_data.head()[\"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n",
    "total = 0\n",
    "above_thresh = 0\n",
    "for review in train_data[\"tokenized\"]:\n",
    "  if len(review) > max:\n",
    "    max = len(review)\n",
    "  total += len(review)\n",
    "  if len(review) > 400:\n",
    "    above_thresh += 1\n",
    "print(max)\n",
    "print(total/25000)\n",
    "print(above_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voacb Map\n",
    "Create a vocab map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reversed_train_vocab = generate_vocab_map(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(train_vocab, train_data)\n",
    "train_dataset, val_dataset = random_split(train_dataset,[0.9,0.1])\n",
    "test_dataset  = ReviewDataset(train_vocab, test_data)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "test_sampler  = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSentimentTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(SimpleSentimentTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = nn.Embedding(300, embed_dim) # max sequence length = 300\n",
    "        encoder_layers = TransformerEncoderLayer(embed_dim, num_heads, dim_feedforward=embed_dim, dropout=dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, 2) # num_classes = 2\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_length = x.size(1)\n",
    "        pos = torch.arange(0, seq_length).unsqueeze(0).repeat(x.size(0), 1).to(x.device)\n",
    "        x = self.embedding(x) + self.pos_encoder(pos)\n",
    "        x = x.permute(1, 0, 2)  # change to (seq_len, batch_size, embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)  # average pooling over sequence length\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_and_f1_score(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    This function takes in two numpy arrays and computes the accuracy and F1 score\n",
    "    between them. You can use the imported sklearn functions to do this.\n",
    "\n",
    "    Args:\n",
    "        y_true (list) : A 1D numpy array of ground truth labels\n",
    "        y_predicted (list) : A 1D numpy array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float) : The accuracy of the predictions\n",
    "        f1_score (float) : The F1 score of the predictions\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "\n",
    "    f1 = f1_score(y_true, y_predicted, average='macro')\n",
    "\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(classes)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(loss_type='ce'):\n",
    "    criterion = None\n",
    "\n",
    "    ## YOUR CODE STARTS HERE ##\n",
    "    if loss_type == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    ## YOUR CODE ENDS HERE ##\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, learning_rate):\n",
    "    \"\"\"\n",
    "    This function takes a model and a learning rate, and returns an optimizer.\n",
    "    Feel free to experiment with different optimizers.\n",
    "    \"\"\"\n",
    "    optimizer = None\n",
    "\n",
    "    ## YOUR CODE STARTS HERE ##\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ## YOUR CODE ENDS HERE ##\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, criterion, optimizer, iterator, epoch, save_every=10):\n",
    "    \"\"\"\n",
    "    This function is used to train a model for one epoch.\n",
    "    :param model: The model to be trained\n",
    "    :param criterion: The loss function\n",
    "    :param optim: The optimizer\n",
    "    :param iterator: The training data iterator\n",
    "    :return: The average loss for this epoch\n",
    "    \"\"\"\n",
    "    model.train() # Is used to put the model in training mode\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(iterator, total=len(iterator), desc=\"Training Model\"):\n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        # remove this when you add your implementation\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "\n",
    "        # output = output.long()\n",
    "        y = y.long()\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the validation set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x, y in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x, y = x.to(device), y.to(device)\n",
    "         output = model(x)\n",
    "\n",
    "        #  output = output.long()\n",
    "         y = y.long()\n",
    "\n",
    "         loss = criterion(output, y)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(y.tolist())\n",
    "         predicted = torch.argmax(output, dim=1)\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams_transformer():\n",
    "    VOCAB_SIZE = len(train_vocab)\n",
    "    EMBED_DIM = 128\n",
    "    NUM_HEADS = 4\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.1\n",
    "    LEARNING_RATE = 0.001\n",
    "    EPOCHS = 10\n",
    "    return VOCAB_SIZE, EMBED_DIM, NUM_HEADS, NUM_LAYERS, DROPOUT, LEARNING_RATE, EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_model(vocab_size, embedding_dim, num_heads, num_layers, dropout):\n",
    "    model = SimpleSentimentTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=embedding_dim,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE, EMBED_DIM, NUM_HEADS, NUM_LAYERS, DROPOUT, LEARNING_RATE, EPOCHS = get_hyperparams_transformer()\n",
    "\n",
    "transformer_model = get_transformer_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "criterion = get_criterion()\n",
    "optimizer = get_optimizer(transformer_model, LEARNING_RATE)\n",
    "train_loss_over_time_transformer = []\n",
    "val_loss_over_time_transformer = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_loop(transformer_model, criterion, optimizer, train_iterator, epoch, save_every=2)\n",
    "    true, pred, val_loss = val_loop(transformer_model, criterion, train_iterator) # change to val\n",
    "    accuracy, f1 = get_accuracy_and_f1_score(true, pred)\n",
    "    print(f\"Epoch {epoch+1} -- Train_Loss: {train_loss} -- Val_Loss: {val_loss} -- Val_Accuracy: {accuracy} -- Val_F1: {f1}\")\n",
    "    train_loss_over_time_transformer.append(train_loss)\n",
    "    val_loss_over_time_transformer.append(val_loss)\n",
    "save_checkpoint(transformer_model, 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(train_loss_over_time_transformer, val_loss_over_time_transformer, 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate, epochs, embedding_dim = get_hyperparams_transformer()\n",
    "transformer_model = get_transformer_model(vocab_size= len(train_vocab.keys()), embedding_dim = embedding_dim).to(device)\n",
    "load_checkpoint(transformer_model, 'transformer', map_location=device)\n",
    "\n",
    "# evaluate model\n",
    "true, pred, val_loss = val_loop(transformer_model, criterion, val_iterator)\n",
    "accuracy, f1 = get_accuracy_and_f1_score(true, pred)\n",
    "print(f\"Final Validation Accuracy: {accuracy}\")\n",
    "print(f\"Final Validation F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(true, pred, classes=id2label.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
