{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Interpreter\n",
    "We train a simple transformer for sentiment analysis on movie reviews, extract interpretable features using SAE and generate explanations using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataPreprocessing import *\n",
    "import pandas as pd\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1591f3230>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data\n",
    "Data is loaded from 'dataset' folder. There are 50,000 reviews in the data total. 25,000 for training and 25,000 testing. Reviews have label, either positive or negative. There are an equal number of positive and negative reviews in the each dataset. Each review is a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder path were dataset is located\n",
    "path = 'dataset/'\n",
    "#initialize empty lists to hold data\n",
    "train_pos, train_neg, test_pos, test_neg = [], [], [], []\n",
    "#create a dictionary where the key is the relative path to data and value is empty list\n",
    "sets_dict = {'train/pos/': train_pos, 'train/neg/': train_neg, 'test/pos/': test_pos, 'test/neg/': test_neg}\n",
    "#loop through dictionary to read from files and populate empty lists\n",
    "for dataset in sets_dict:\n",
    "        file_list = [file for file in os.listdir(os.path.join(path, dataset)) if file.endswith('.txt')]\n",
    "        file_list = sorted(file_list)\n",
    "        load_data(os.path.join(path, dataset), file_list, sets_dict[dataset])\n",
    "#Covert lists to pandas dataframes and combine to form train and test datasets\n",
    "train_data = pd.concat([pd.DataFrame({'review': train_pos, 'label':1}), pd.DataFrame({'review': train_neg, 'label':0})], axis = 0, ignore_index=True)\n",
    "test_data = pd.concat([pd.DataFrame({'review': test_pos, 'label':1}), pd.DataFrame({'review': test_neg, 'label':0})], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
      "3  This is easily the most underrated film inn th...      1\n",
      "4  This is not the typical Mel Brooks film. It wa...      1\n",
      "                                                  review  label\n",
      "24995  Towards the end of the movie, I felt it was to...      0\n",
      "24996  This is the kind of movie that my enemies cont...      0\n",
      "24997  I saw 'Descent' last night at the Stockholm Fi...      0\n",
      "24998  Some films that you pick up for a pound turn o...      0\n",
      "24999  This is one of the dumbest films, I've ever se...      0\n"
     ]
    }
   ],
   "source": [
    "#Visualize train_data dataframe\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  I went and saw this movie last night after bei...      1\n",
      "1  Actor turned director Bill Paxton follows up h...      1\n",
      "2  As a recreational golfer with some knowledge o...      1\n",
      "3  I saw this film in a sneak preview, and it is ...      1\n",
      "4  Bill Paxton has taken the true story of the 19...      1\n",
      "                                                  review  label\n",
      "24995  I occasionally let my kids watch this garbage ...      0\n",
      "24996  When all we have anymore is pretty much realit...      0\n",
      "24997  The basic genre is a thriller intercut with an...      0\n",
      "24998  Four things intrigued me as to this film - fir...      0\n",
      "24999  David Bryce's comments nearby are exceptionall...      0\n"
     ]
    }
   ],
   "source": [
    "#Visualize test_data dataframe\n",
    "print(test_data.shape)\n",
    "print(test_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Data\n",
    "Tokenize each review using spacy english tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tokenized\"] = train_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))\n",
    "test_data[\"tokenized\"] = test_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [bromwell, high, is, a, cartoon, comedy, ., it...\n",
      "1    [homelessness, (, or, houselessness, as, georg...\n",
      "2    [brilliant, over, -, acting, by, lesley, ann, ...\n",
      "3    [this, is, easily, the, most, underrated, film...\n",
      "4    [this, is, not, the, typical, mel, brooks, fil...\n",
      "Name: tokenized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Examine tokenized reviews\n",
    "print(train_data.head()[\"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2772\n",
      "273.77724\n",
      "4537\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "total = 0\n",
    "above_thresh = 0\n",
    "for review in train_data[\"tokenized\"]:\n",
    "  if len(review) > max:\n",
    "    max = len(review)\n",
    "  total += len(review)\n",
    "  if len(review) > 400:\n",
    "    above_thresh += 1\n",
    "print(max)\n",
    "print(total/25000)\n",
    "print(above_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voacb Map\n",
    "Create a vocab map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reversed_train_vocab = generate_vocab_map(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(train_vocab, train_data)\n",
    "train_dataset, val_dataset = random_split(train_dataset,[0.9,0.1])\n",
    "test_dataset  = ReviewDataset(train_vocab, test_data)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "test_sampler  = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
