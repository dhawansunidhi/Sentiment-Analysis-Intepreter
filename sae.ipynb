{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataPreprocessing import *\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x196270ee590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, model_name, loss_fn='ce'):\n",
    "    file_path = os.path.join(os.getcwd(), 'model_weights', f'checkpoint_{model_name}_{loss_fn}.pt')\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'model_weights'), exist_ok=True)\n",
    "    checkpoint = { # create a dictionary with all the state information\n",
    "        'model_state_dict': model.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Checkpoint saved to {file_path}\")\n",
    "\n",
    "def load_checkpoint(model, model_name, loss_fn='ce', map_location='cpu'):\n",
    "    file_path = os.path.join(os.getcwd(), 'model_weights', f'checkpoint_{model_name}_{loss_fn}.pt')\n",
    "    checkpoint = torch.load(file_path, map_location=map_location) # load the checkpoint, ensure correct device\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss_over_time, val_loss_over_time, model_name):\n",
    "    epochs = range(1, len(train_loss_over_time) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss_over_time, color='red', label='Train Loss')\n",
    "    plt.plot(epochs, val_loss_over_time, color='blue', label='Val Loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss for {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder path were dataset is located\n",
    "path = 'dataset/'\n",
    "#initialize empty lists to hold data\n",
    "train_pos, train_neg, test_pos, test_neg = [], [], [], []\n",
    "#create a dictionary where the key is the relative path to data and value is empty list\n",
    "sets_dict = {'train/pos/': train_pos, 'train/neg/': train_neg, 'test/pos/': test_pos, 'test/neg/': test_neg}\n",
    "#loop through dictionary to read from files and populate empty lists\n",
    "for dataset in sets_dict:\n",
    "        file_list = [file for file in os.listdir(os.path.join(path, dataset)) if file.endswith('.txt')]\n",
    "        file_list = sorted(file_list)\n",
    "        load_data(os.path.join(path, dataset), file_list, sets_dict[dataset])\n",
    "#Covert lists to pandas dataframes and combine to form train and test datasets\n",
    "train_data = pd.concat([pd.DataFrame({'review': train_pos, 'label':1}), pd.DataFrame({'review': train_neg, 'label':0})], axis = 0, ignore_index=True)\n",
    "test_data = pd.concat([pd.DataFrame({'review': test_pos, 'label':1}), pd.DataFrame({'review': test_neg, 'label':0})], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
      "3  This is easily the most underrated film inn th...      1\n",
      "4  This is not the typical Mel Brooks film. It wa...      1\n",
      "                                                  review  label\n",
      "24995  Towards the end of the movie, I felt it was to...      0\n",
      "24996  This is the kind of movie that my enemies cont...      0\n",
      "24997  I saw 'Descent' last night at the Stockholm Fi...      0\n",
      "24998  Some films that you pick up for a pound turn o...      0\n",
      "24999  This is one of the dumbest films, I've ever se...      0\n"
     ]
    }
   ],
   "source": [
    "#Visualize train_data dataframe\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "                                              review  label\n",
      "0  I went and saw this movie last night after bei...      1\n",
      "1  Actor turned director Bill Paxton follows up h...      1\n",
      "2  As a recreational golfer with some knowledge o...      1\n",
      "3  I saw this film in a sneak preview, and it is ...      1\n",
      "4  Bill Paxton has taken the true story of the 19...      1\n",
      "                                                  review  label\n",
      "24995  I occasionally let my kids watch this garbage ...      0\n",
      "24996  When all we have anymore is pretty much realit...      0\n",
      "24997  The basic genre is a thriller intercut with an...      0\n",
      "24998  Four things intrigued me as to this film - fir...      0\n",
      "24999  David Bryce's comments nearby are exceptionall...      0\n"
     ]
    }
   ],
   "source": [
    "#Visualize test_data dataframe\n",
    "print(test_data.shape)\n",
    "print(test_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tokenized\"] = train_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))\n",
    "test_data[\"tokenized\"] = test_data[\"review\"].apply(lambda x: tokenize(clean_text(x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [bromwell, high, is, a, cartoon, comedy, ., it...\n",
      "1    [homelessness, (, or, houselessness, as, georg...\n",
      "2    [brilliant, over, -, acting, by, lesley, ann, ...\n",
      "3    [this, is, easily, the, most, underrated, film...\n",
      "4    [this, is, not, the, typical, mel, brooks, fil...\n",
      "Name: tokenized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Examine tokenized reviews\n",
    "print(train_data.head()[\"tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2772\n",
      "273.77724\n",
      "4537\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "total = 0\n",
    "above_thresh = 0\n",
    "for review in train_data[\"tokenized\"]:\n",
    "  if len(review) > max:\n",
    "    max = len(review)\n",
    "  total += len(review)\n",
    "  if len(review) > 400:\n",
    "    above_thresh += 1\n",
    "print(max)\n",
    "print(total/25000)\n",
    "print(above_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, reversed_train_vocab = generate_vocab_map(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(RANDOM_SEED)\n",
    "\n",
    "train_dataset = ReviewDataset(train_vocab, train_data)\n",
    "train_dataset, val_dataset = random_split(train_dataset,[0.9,0.1], generator=generator1)\n",
    "test_dataset  = ReviewDataset(train_vocab, test_data)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "test_sampler  = RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "val_iterator = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
    "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSentimentTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(SimpleSentimentTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = nn.Embedding(3000, embed_dim) # max sequence length = 400\n",
    "        encoder_layers = TransformerEncoderLayer(embed_dim, num_heads, dim_feedforward=embed_dim, dropout=dropout)\n",
    "        # self.encoder_norm = nn.LayerNorm(embed_dim)\n",
    "        # self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers, norm=self.encoder_norm)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, 2) # num_classes = 2\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_length = x.size(1)\n",
    "        pos = torch.arange(0, seq_length).unsqueeze(0).repeat(x.size(0), 1).to(x.device)\n",
    "        x = self.embedding(x) + self.pos_encoder(pos)\n",
    "        x = x.permute(1, 0, 2)  # change to (seq_len, batch_size, embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)  # average pooling over sequence length\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_and_f1_score(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    This function takes in two numpy arrays and computes the accuracy and F1 score\n",
    "    between them. You can use the imported sklearn functions to do this.\n",
    "\n",
    "    Args:\n",
    "        y_true (list) : A 1D numpy array of ground truth labels\n",
    "        y_predicted (list) : A 1D numpy array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float) : The accuracy of the predictions\n",
    "        f1_score (float) : The F1 score of the predictions\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "\n",
    "    f1 = f1_score(y_true, y_predicted, average='macro')\n",
    "\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(classes)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity_penalty_kl(encoded):\n",
    "        rho_hat = torch.mean(encoded, dim=0)\n",
    "        rho = self.sparsity_target\n",
    "        epsilon = 1e-8\n",
    "        rho_hat = torch.clamp(rho_hat, min=epsilon, max=1 - epsilon)\n",
    "        kl_divergence = rho * torch.log(rho / rho_hat) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat))\n",
    "        sparsity_penalty = torch.sum(kl_divergence)\n",
    "        return self.sparsity_lambda * sparsity_penalty\n",
    "\n",
    "def sparsity_penalty_l1(encoded):\n",
    "        return torch.sum(encoded, dim=1).mean()\n",
    "\n",
    "def sparse_reconstruction_loss(x_hat, x, encoded):\n",
    "        sparsity_penalty = sparsity_penalty_l1(encoded)\n",
    "        mse_loss = F.mse_loss(x_hat, x, reduction='mean')\n",
    "        return sparsity_penalty + mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(loss_type='ce'):\n",
    "    criterion = None\n",
    "\n",
    "    ## YOUR CODE STARTS HERE ##\n",
    "    if loss_type == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif loss_type == 'sr':\n",
    "        criterion = sparse_reconstruction_loss\n",
    "    elif loss_type == 'mse':\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "    ## YOUR CODE ENDS HERE ##\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, learning_rate):\n",
    "    \"\"\"\n",
    "    This function takes a model and a learning rate, and returns an optimizer.\n",
    "    Feel free to experiment with different optimizers.\n",
    "    \"\"\"\n",
    "    optimizer = None\n",
    "\n",
    "    ## YOUR CODE STARTS HERE ##\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ## YOUR CODE ENDS HERE ##\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, criterion, optimizer, iterator, epoch, save_every=10):\n",
    "    \"\"\"\n",
    "    This function is used to train a model for one epoch.\n",
    "    :param model: The model to be trained\n",
    "    :param criterion: The loss function\n",
    "    :param optim: The optimizer\n",
    "    :param iterator: The training data iterator\n",
    "    :return: The average loss for this epoch\n",
    "    \"\"\"\n",
    "    model.train() # Is used to put the model in training mode\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(iterator, total=len(iterator), desc=\"Training Model\"):\n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        # remove this when you add your implementation\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "\n",
    "        # output = output.long()\n",
    "        y = y.long()\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the validation set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x, y in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x, y = x.to(device), y.to(device)\n",
    "         output = model(x)\n",
    "\n",
    "        #  output = output.long()\n",
    "         y = y.long()\n",
    "\n",
    "         loss = criterion(output, y)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(y.tolist())\n",
    "         predicted = torch.argmax(output, dim=1)\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the test set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x, y in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x, y = x.to(device), y.to(device)\n",
    "         output = model(x)\n",
    "\n",
    "        #  output = output.long()\n",
    "         y = y.long()\n",
    "\n",
    "         loss = criterion(output, y)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(y.tolist())\n",
    "         predicted = torch.argmax(output, dim=1)\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams_transformer():\n",
    "    VOCAB_SIZE = len(train_vocab)\n",
    "    EMBED_DIM = 4\n",
    "    NUM_HEADS = 1\n",
    "    NUM_LAYERS = 1\n",
    "    DROPOUT = 0.1\n",
    "    LEARNING_RATE = 0.015\n",
    "    EPOCHS = 2\n",
    "    return VOCAB_SIZE, EMBED_DIM, NUM_HEADS, NUM_LAYERS, DROPOUT, LEARNING_RATE, EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_model(vocab_size, embedding_dim, num_heads, num_layers, dropout):\n",
    "    model = SimpleSentimentTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=embedding_dim,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadar\\AppData\\Local\\Temp\\ipykernel_24212\\1142292354.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path, map_location=map_location) # load the checkpoint, ensure correct device\n",
      "Evaluating Model:   0%|          | 0/391 [00:00<?, ?it/s]c:\\Users\\aadar\\miniconda3\\envs\\cs7650-hw\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Evaluating Model: 100%|██████████| 391/391 [00:12<00:00, 30.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.87372\n",
      "Final Test F1-Score: 0.873695102576532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE, EMBED_DIM, NUM_HEADS, NUM_LAYERS, DROPOUT, LEARNING_RATE, EPOCHS = get_hyperparams_transformer()\n",
    "\n",
    "transformer_model = get_transformer_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "load_checkpoint(transformer_model, 'transformer2', map_location=device)\n",
    "criterion = get_criterion()\n",
    "\n",
    "# evaluate model\n",
    "true, pred, val_loss = test_loop(transformer_model, criterion, test_iterator)\n",
    "accuracy, f1 = get_accuracy_and_f1_score(true, pred)\n",
    "print(f\"Final Test Accuracy: {accuracy}\")\n",
    "print(f\"Final Test F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(true, pred, classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {'fc': torch.empty((0, 4), device=device)}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = torch.cat([activation[name], output.detach()]) \n",
    "    return hook\n",
    "\n",
    "handle = transformer_model.dropout.register_forward_hook(get_activation('fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model: 100%|██████████| 352/352 [00:06<00:00, 50.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22500, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 69.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model: 100%|██████████| 391/391 [00:04<00:00, 78.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "true, pred, train_loss = test_loop(transformer_model, criterion, train_iterator)\n",
    "act_train = activation['fc'].clone()\n",
    "print(act_train.shape)\n",
    "\n",
    "activation = {'fc': torch.empty((0, 4), device=device)}\n",
    "true, pred, val_loss = test_loop(transformer_model, criterion, val_iterator)\n",
    "act_val = activation['fc'].clone()\n",
    "print(act_val.shape)\n",
    "\n",
    "activation = {'fc': torch.empty((0, 4), device=device)}\n",
    "true, pred, test_loss = test_loop(transformer_model, criterion, test_iterator)\n",
    "act_test = activation['fc'].clone()\n",
    "print(act_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAEEncoder(nn.Module):\n",
    "    def __init__(self, latent_size=64):\n",
    "        super(SAEEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, latent_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "class SAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_size=64):\n",
    "        super(SAEDecoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_size, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, latent_size=64):\n",
    "        super(SAE, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.W = nn.Parameter(torch.rand(4, latent_size)) # tied weights for training!\n",
    "        self.b = nn.Parameter(torch.rand(latent_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = F.relu(torch.mm(x, self.W) + self.b)\n",
    "        decoded = torch.mm(encoded, torch.transpose(self.W, 0, 1))\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSAE(nn.Module):\n",
    "    def __init__(self, latent_size=64, top_k=16):\n",
    "        super(KSAE, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.top_k = top_k\n",
    "        self.W = nn.Parameter(torch.rand(4, latent_size)) # tied weights for training!\n",
    "        self.b = nn.Parameter(torch.rand(latent_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded_acts = F.relu(torch.mm(x, self.W) + self.b)\n",
    "        encoded_topk = torch.topk(encoded_acts, self.top_k, dim=-1)\n",
    "        encoded_topk = torch.zeros_like(encoded_acts).scatter(\n",
    "            -1, encoded_topk.indices, encoded_topk.values\n",
    "        )\n",
    "        decoded = torch.mm(encoded_topk, torch.transpose(self.W, 0, 1))\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_sae(model, criterion, optimizer, iterator, epoch, save_every=10):\n",
    "    \"\"\"\n",
    "    This function is used to train a model for one epoch.\n",
    "    :param model: The model to be trained\n",
    "    :param criterion: The loss function\n",
    "    :param optim: The optimizer\n",
    "    :param iterator: The training data iterator\n",
    "    :return: The average loss for this epoch\n",
    "    \"\"\"\n",
    "    model.train() # Is used to put the model in training mode\n",
    "    total_loss = 0\n",
    "    for x in tqdm(iterator, total=len(iterator), desc=\"Training Model\"):\n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        # remove this when you add your implementation\n",
    "        \n",
    "        x = x[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        encoded, decoded = model(x)\n",
    "\n",
    "        # print(encoded.shape())\n",
    "        # print(decoded.shape())\n",
    "\n",
    "        loss = criterion(decoded, x, encoded)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop_sae(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the validation set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x = x[0].to(device)\n",
    "         encoded, decoded = model(x)\n",
    "\n",
    "         loss = criterion(decoded, x, encoded)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(x.tolist())\n",
    "         predicted = decoded\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop_sae(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the test set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x = x[0].to(device) \n",
    "         encoded, decoded = model(x)\n",
    "\n",
    "         loss = criterion(decoded, x, encoded)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(x.tolist())\n",
    "         predicted = decoded\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_ksae(model, criterion, optimizer, iterator, epoch, save_every=10):\n",
    "    \"\"\"\n",
    "    This function is used to train a model for one epoch.\n",
    "    :param model: The model to be trained\n",
    "    :param criterion: The loss function\n",
    "    :param optim: The optimizer\n",
    "    :param iterator: The training data iterator\n",
    "    :return: The average loss for this epoch\n",
    "    \"\"\"\n",
    "    model.train() # Is used to put the model in training mode\n",
    "    total_loss = 0\n",
    "    for x in tqdm(iterator, total=len(iterator), desc=\"Training Model\"):\n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        # remove this when you add your implementation\n",
    "        x = x[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat = model(x)\n",
    "\n",
    "        loss = criterion(x_hat, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop_ksae(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the validation set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x = x[0].to(device)\n",
    "         x_hat = model(x)\n",
    "\n",
    "         loss = criterion(x_hat, x)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(x.tolist())\n",
    "         predicted = x_hat\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop_ksae(model, criterion, iterator):\n",
    "    \"\"\"\n",
    "    This function is used to evaluate a model on the test set.\n",
    "    :param model: The model to be evaluated\n",
    "    :param iterator: The validation data iterator\n",
    "    :return: true: a Python boolean array of all the ground truth values\n",
    "             pred: a Python boolean array of all model predictions.\n",
    "            average_loss: The average loss over the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    true, pred = [], []\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for x in tqdm(iterator, total=len(iterator), desc=\"Evaluating Model\"):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "         # remove this when you add your implementation\n",
    "         x = x[0].to(device) \n",
    "         x_hat = model(x)\n",
    "\n",
    "         loss = criterion(x_hat, x)\n",
    "\n",
    "         total_loss += loss.item()\n",
    "         true.extend(x.tolist())\n",
    "         predicted = x_hat\n",
    "         pred.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    average_loss = total_loss / len(iterator)\n",
    "    return true, pred, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_train_dataset = torch.utils.data.TensorDataset(act_train)\n",
    "sae_val_dataset = torch.utils.data.TensorDataset(act_val)\n",
    "sae_test_dataset = torch.utils.data.TensorDataset(act_test)\n",
    "\n",
    "sae_train_sampler = RandomSampler(sae_train_dataset)\n",
    "sae_val_sampler = RandomSampler(sae_val_dataset)\n",
    "sae_test_sampler  = RandomSampler(sae_test_dataset)\n",
    "\n",
    "sae_train_iterator = DataLoader(sae_train_dataset, batch_size=BATCH_SIZE, sampler=sae_train_sampler)\n",
    "sae_val_iterator = DataLoader(sae_val_dataset, batch_size=BATCH_SIZE, sampler=sae_val_sampler)\n",
    "sae_test_iterator  = DataLoader(sae_test_dataset, batch_size=BATCH_SIZE, sampler=sae_test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams_sae():\n",
    "    LATENT_SIZE = 64\n",
    "    LEARNING_RATE = 0.001\n",
    "    EPOCHS = 20\n",
    "    return LATENT_SIZE, LEARNING_RATE, EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sae_model(latent_size):\n",
    "    model = SAE(\n",
    "        latent_size=latent_size\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 572.51it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 531.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Train_Loss: 115.90694405815817 -- Val_Loss: 37.821691036224365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:01<00:00, 344.46it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 347.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -- Train_Loss: 22.739119391549718 -- Val_Loss: 13.687061214447022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 440.65it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 125.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -- Train_Loss: 10.322361318902535 -- Val_Loss: 7.813504219055176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 817.98it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1536.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -- Train_Loss: 6.268192807381803 -- Val_Loss: 4.829123723506927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 771.84it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1597.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -- Train_Loss: 3.86755272610621 -- Val_Loss: 2.890938913822174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 845.81it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1353.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -- Train_Loss: 2.2769046547737988 -- Val_Loss: 1.663197010755539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 785.44it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1692.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -- Train_Loss: 1.4409687989814715 -- Val_Loss: 1.0655718833208083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 829.19it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1698.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -- Train_Loss: 0.9868695498867468 -- Val_Loss: 0.7539998009800911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 766.26it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1507.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -- Train_Loss: 0.7874508518725634 -- Val_Loss: 0.6995899811387062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 771.21it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1353.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -- Train_Loss: 0.777327302674001 -- Val_Loss: 0.7024096712470055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 422.94it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 554.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -- Train_Loss: 0.7748688059774312 -- Val_Loss: 0.6949595302343369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 352.56it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1229.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -- Train_Loss: 0.7735352456908334 -- Val_Loss: 0.6893061749637127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 821.06it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1700.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -- Train_Loss: 0.7723037754608826 -- Val_Loss: 0.6892831690609456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 830.76it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1192.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -- Train_Loss: 0.7717905097048391 -- Val_Loss: 0.7028997093439102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 772.89it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1174.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 -- Train_Loss: 0.771458737552166 -- Val_Loss: 0.6901075914502144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 527.13it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 541.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 -- Train_Loss: 0.7713547669012438 -- Val_Loss: 0.6972717702388763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 465.27it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1737.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 -- Train_Loss: 0.7709101748398759 -- Val_Loss: 0.6912491843104362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 853.87it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1452.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 -- Train_Loss: 0.7707568681375547 -- Val_Loss: 0.7034282222390175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 886.97it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1769.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 -- Train_Loss: 0.7705085993829098 -- Val_Loss: 0.71244927495718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 747.22it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1480.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 -- Train_Loss: 0.7704481445252895 -- Val_Loss: 0.7088145345449448\n",
      "Checkpoint saved to c:\\Users\\aadar\\Documents\\Sentiment-Analysis-Intepreter\\model_weights\\checkpoint_sae_ce.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LATENT_SIZE, LEARNING_RATE, EPOCHS = get_hyperparams_sae()\n",
    "\n",
    "sae_model = get_sae_model(\n",
    "    latent_size=LATENT_SIZE\n",
    ").to(device)\n",
    "\n",
    "criterion = get_criterion(loss_type='sr')\n",
    "optimizer = get_optimizer(sae_model, LEARNING_RATE)\n",
    "train_loss_over_time_sae = []\n",
    "val_loss_over_time_sae = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_loop_sae(sae_model, criterion, optimizer, sae_train_iterator, epoch, save_every=2)\n",
    "    true, pred, val_loss = val_loop_sae(sae_model, criterion, sae_val_iterator) # change to val\n",
    "    # accuracy, f1 = get_accuracy_and_f1_score(true, pred)\n",
    "    print(f\"Epoch {epoch+1} -- Train_Loss: {train_loss} -- Val_Loss: {val_loss}\")\n",
    "    train_loss_over_time_sae.append(train_loss)\n",
    "    val_loss_over_time_sae.append(val_loss)\n",
    "save_checkpoint(sae_model, 'sae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams_ksae():\n",
    "    LATENT_SIZE = 64\n",
    "    TOP_K = 8\n",
    "    LEARNING_RATE = 0.001\n",
    "    EPOCHS = 20\n",
    "    return LATENT_SIZE, TOP_K, LEARNING_RATE, EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ksae_model(latent_size, top_k):\n",
    "    model = KSAE(\n",
    "        latent_size=latent_size, \n",
    "        top_k=top_k\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:01<00:00, 313.47it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 125.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Train_Loss: 10.745835868472403 -- Val_Loss: 2.9339495837688445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:01<00:00, 327.30it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 472.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -- Train_Loss: 1.2234440019608221 -- Val_Loss: 0.2005251009017229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 390.58it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1479.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -- Train_Loss: 0.09388757425106385 -- Val_Loss: 0.04028554325923324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 697.76it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1353.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -- Train_Loss: 0.0318373614678752 -- Val_Loss: 0.028905810066498817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 714.34it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1283.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -- Train_Loss: 0.025980115741152655 -- Val_Loss: 0.023990646889433264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 689.33it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1427.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -- Train_Loss: 0.02210186929071576 -- Val_Loss: 0.020577374286949633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 435.11it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1449.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -- Train_Loss: 0.018836352270392872 -- Val_Loss: 0.017284511018078774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 735.98it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1226.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -- Train_Loss: 0.015244740929285234 -- Val_Loss: 0.013514821394346654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 777.33it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1156.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -- Train_Loss: 0.012171041907012377 -- Val_Loss: 0.010553843178786337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 719.98it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1563.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -- Train_Loss: 0.009802857441668906 -- Val_Loss: 0.008640975120943039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 802.01it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1373.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -- Train_Loss: 0.008307325820417398 -- Val_Loss: 0.007581516809295863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 743.02it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1478.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -- Train_Loss: 0.006840597515375438 -- Val_Loss: 0.005798023357056081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 738.97it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1423.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -- Train_Loss: 0.005428083033951803 -- Val_Loss: 0.005334848043275997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 729.51it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1324.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -- Train_Loss: 0.005026032684492582 -- Val_Loss: 0.0049702703079674395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 356.59it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 466.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 -- Train_Loss: 0.004660531484246762 -- Val_Loss: 0.004568113427376374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 354.35it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 470.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 -- Train_Loss: 0.004226514714404898 -- Val_Loss: 0.0041197912476491185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:01<00:00, 348.96it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 465.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 -- Train_Loss: 0.0038456598631455563 -- Val_Loss: 0.0035493712523020802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 470.70it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1284.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 -- Train_Loss: 0.003409419911225665 -- Val_Loss: 0.003350826827227138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 740.77it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1223.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 -- Train_Loss: 0.0031187592973186506 -- Val_Loss: 0.002988996359636076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 352/352 [00:00<00:00, 718.35it/s]\n",
      "Evaluating Model: 100%|██████████| 40/40 [00:00<00:00, 1329.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 -- Train_Loss: 0.0029763416476436596 -- Val_Loss: 0.0033350808604154735\n",
      "Checkpoint saved to c:\\Users\\aadar\\Documents\\Sentiment-Analysis-Intepreter\\model_weights\\checkpoint_ksae_ce.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LATENT_SIZE, TOP_K, LEARNING_RATE, EPOCHS = get_hyperparams_ksae()\n",
    "\n",
    "ksae_model = get_ksae_model(\n",
    "    latent_size=LATENT_SIZE, \n",
    "    top_k=TOP_K\n",
    ").to(device)\n",
    "\n",
    "criterion = get_criterion(loss_type='mse')\n",
    "optimizer = get_optimizer(ksae_model, LEARNING_RATE)\n",
    "train_loss_over_time_ksae = []\n",
    "val_loss_over_time_ksae = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_loop_ksae(ksae_model, criterion, optimizer, sae_train_iterator, epoch, save_every=2)\n",
    "    true, pred, val_loss = val_loop_ksae(ksae_model, criterion, sae_val_iterator) # change to val\n",
    "    # accuracy, f1 = get_accuracy_and_f1_score(true, pred)\n",
    "    print(f\"Epoch {epoch+1} -- Train_Loss: {train_loss} -- Val_Loss: {val_loss}\")\n",
    "    train_loss_over_time_ksae.append(train_loss)\n",
    "    val_loss_over_time_ksae.append(val_loss)\n",
    "save_checkpoint(ksae_model, 'ksae')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7650-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
